{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633df329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unknown args: ['--f=/run/user/1004/jupyter/runtime/kernel-v3ebb5183588a0404d0c36c4c59164d09354c3f9f5.json']\n",
      "ðŸ“¡ Training Start\n",
      "ðŸ”§ SNR=11.0, inner channel c=8, ratio=0.17\n",
      "Found checkpoint: ./out/checkpoints/IMAGENET_8_19.0_0.17_AWGN_10_21h24m09s_on_Jul_18_2025/epoch_502.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1129882/851009620.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
      "/home/tinguyen/anaconda3/envs/JSCC2/lib/python3.11/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Epoch:   0%|          | 0/7500 [00:00<?, ?it/s]/home/MATLAB_DATA/TiNguyen/Deep-JSCC-PyTorch/binary_converter.py:54: UserWarning: Some absolute float values are below min_val=6.103515625e-05. They will be clamped.\n",
      "  warnings.warn(f\"Some absolute float values are below min_val={min_val}. They will be clamped.\")\n",
      "/home/MATLAB_DATA/TiNguyen/Deep-JSCC-PyTorch/binary_converter.py:62: UserWarning: Some absolute float values are above max_val=10. They will be clamped.\n",
      "  warnings.warn(f\"Some absolute float values are above max_val={max_val}. They will be clamped.\")\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec 17 00:00:00 2023\n",
    "@author: chun (refactored)\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from fractions import Fraction\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from model2 import DeepJSCC, ratio2filtersize\n",
    "from utils import image_normalization, set_seed, view_model_param\n",
    "from dataset import Vanilla\n",
    "\n",
    "\n",
    "import torch\n",
    "from model import  DeepJSCC as DJ\n",
    "\n",
    "def config_parser_pipeline():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', default='imagenet', type=str,\n",
    "                        choices=['cifar10', 'imagenet'], help='Dataset name')\n",
    "    parser.add_argument('--out', default='./out', type=str, help='Output path for logs and checkpoints')\n",
    "    parser.add_argument('--disable_tqdm', action='store_true', help='Disable tqdm progress bars')\n",
    "    parser.add_argument('--device', default='cuda:0', type=str, help='Device: cuda:0 / cpu')\n",
    "    parser.add_argument('--parallel', action='store_true', help='Use DataParallel if multiple GPUs are available')\n",
    "    parser.add_argument('--snr_list', default=['11', '19'], nargs='+',\n",
    "                        help='List of SNR values (e.g. 5 10 15)')\n",
    "    parser.add_argument('--ratio_list', default=['1/6', '1/12'], nargs='+',\n",
    "                        help='List of channel ratios (e.g. 1/6 1/12)')\n",
    "    parser.add_argument('--channel', default='Rayleigh', type=str,\n",
    "                        choices=['AWGN', 'Rayleigh'], help='Channel type')\n",
    "\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    if unknown:\n",
    "        print(f\"Ignoring unknown args: {unknown}\")\n",
    "    return args\n",
    "\n",
    "def auto_find_checkpoint0(dataset, c, snr, ratio, channel, base_dir='./out/checkpoints'):\n",
    "    prefix = f\"{dataset.upper()}_{c}_{snr}_{ratio:.2f}_{channel}\"\n",
    "    candidates = [\n",
    "        os.path.join(base_dir, d)\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(prefix)\n",
    "    ]\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No checkpoint directories found with prefix: {prefix}\")\n",
    "    latest_dir = max(candidates, key=os.path.getmtime)\n",
    "    ckpts = glob.glob(os.path.join(latest_dir, 'epoch_*.pth'))\n",
    "    if not ckpts:\n",
    "        raise FileNotFoundError(f\"No checkpoint files in: {latest_dir}\")\n",
    "    latest_ckpt = sorted(ckpts, key=os.path.getmtime)[-1]\n",
    "    print(f\"Found checkpoint: {latest_ckpt}\")\n",
    "    return latest_ckpt\n",
    "\n",
    "\n",
    "\n",
    "def load_model(ratio):\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    image_size = (64, 64)\n",
    "\n",
    "    # checkpoint_path = f'/home/MATLAB_DATA/TiNguyen/Deep-JSCC-PyTorch/out/checkpoints/IMAGENET_8_19.0_{ratio:.2f}_AWGN_16h18m57s_on_Jul_15_2025/epoch_499.pth'\n",
    "\n",
    "    DATASET = 'imagenet'\n",
    "    CHANNEL_TYPE = 'AWGN'\n",
    "\n",
    "    dummy_img = torch.randn(3, *image_size)\n",
    "    c = ratio2filtersize(dummy_img, ratio)\n",
    "    snr = 19.0\n",
    "    checkpoint_path = auto_find_checkpoint0(DATASET, c, snr, ratio, CHANNEL_TYPE)\n",
    "\n",
    "\n",
    "    model = DJ(c=c, snr=snr, channel_type='AWGN')\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, param, data_loader, Nsamples):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for it, (images, _) in enumerate(data_loader):\n",
    "        images = images.to(param['device'])\n",
    "        optimizer.zero_grad()\n",
    "        # outputs = model(images)\n",
    "        # outputs_Enc = model.Enc(images) put here cause error because trying to use a computational graph that was already freed after a .backward() call \n",
    "        for _ in range(Nsamples):\n",
    "            outputs_Enc = model.Enc(images)\n",
    "\n",
    "            outputs = model.Chan(outputs_Enc)\n",
    "\n",
    "            outputs = model.Dec(outputs)\n",
    "\n",
    "            outputs = image_normalization('denormalization')(outputs)\n",
    "            images1 = image_normalization('denormalization')(images)\n",
    "            loss = model.loss(images1, outputs) if not param['parallel'] else model.module.loss(images1, outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    num_batches = (it + 1) * Nsamples\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, param, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for it, (images, _) in enumerate(data_loader):\n",
    "            images = images.to(param['device'])\n",
    "            outputs_Enc = model.Enc(images)\n",
    "            outputs = model.Chan(outputs_Enc)\n",
    "            outputs = model.Dec(outputs)\n",
    "            outputs = image_normalization('denormalization')(outputs)\n",
    "            images = image_normalization('denormalization')(images)\n",
    "            loss = (model.loss(images, outputs)\n",
    "                    if not param['parallel'] else model.module.loss(images, outputs))\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / (it + 1)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main_pipeline(Nsamples):\n",
    "    args = config_parser_pipeline()\n",
    "    args.snr_list = list(map(float, args.snr_list))\n",
    "    args.ratio_list = [float(Fraction(x)) for x in args.ratio_list]\n",
    "\n",
    "    print(\"ðŸ“¡ Training Start\")\n",
    "    for ratio in args.ratio_list:\n",
    "        for snr in args.snr_list:\n",
    "            params = prepare_params(args, ratio, snr)\n",
    "            train_pipeline(params, Nsamples)\n",
    "\n",
    "\n",
    "def prepare_params(args, ratio, snr):\n",
    "    params = {\n",
    "        'disable_tqdm': args.disable_tqdm,\n",
    "        'dataset': args.dataset,\n",
    "        'out_dir': args.out,\n",
    "        'device': args.device if torch.cuda.is_available() else 'cpu',\n",
    "        'parallel': args.parallel,\n",
    "        'snr': snr,\n",
    "        'ratio': ratio,\n",
    "        'channel': args.channel,\n",
    "    }\n",
    "\n",
    "    if args.dataset == 'cifar10':\n",
    "        params.update({\n",
    "            'batch_size': 64, 'num_workers': 4, 'epochs': 1000,\n",
    "            'init_lr': 1e-3, 'weight_decay': 5e-4,\n",
    "            'if_scheduler': True, 'step_size': 640, 'gamma': 0.1,\n",
    "            'ReduceLROnPlateau': False, 'lr_reduce_factor': 0.5,\n",
    "            'lr_schedule_patience': 15, 'min_lr': 1e-7, 'max_time': 12,\n",
    "            'seed': 42,\n",
    "        })\n",
    "    else:  # imagenet\n",
    "        params.update({\n",
    "            'batch_size': 32, 'num_workers': 4, 'epochs': 750,\n",
    "            'init_lr': 1e-4, 'weight_decay': 5e-4,\n",
    "            'if_scheduler': True, 'gamma': 0.1,\n",
    "            'ReduceLROnPlateau': True, 'lr_reduce_factor': 0.5,\n",
    "            'lr_schedule_patience': 15, 'min_lr': 1e-8, 'max_time': 12,\n",
    "            'seed': 42,\n",
    "        })\n",
    "\n",
    "    set_seed(params['seed'])\n",
    "    return params\n",
    "\n",
    "\n",
    "def train_pipeline(params, Nsamples):\n",
    "    # Data setup\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    if params['dataset'] == 'cifar10':\n",
    "        train_ds = datasets.CIFAR10(root='../dataset/', train=True, download=True, transform=transform)\n",
    "        test_ds = datasets.CIFAR10(root='../dataset/', train=False, download=True, transform=transform)\n",
    "    else:  # imagenet\n",
    "        transform_resize = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "        # train_ds = datasets.ImageFolder('../dataset/ImageNet/train', transform=transform_resize)\n",
    "        # # test_ds = Vanilla('../dataset/ImageNet/val', transform=transform_resize)\n",
    "        # test_ds = datasets.ImageFolder('../dataset/ImageNet/val', transform=transform_resize)\n",
    "\n",
    "        train_ds = datasets.ImageFolder('/home/MATLAB_DATA/TiNguyen/Sentry_Data/train', transform=transform_resize)\n",
    "        # test_ds = Vanilla('../dataset/ImageNet/val', transform=transform_resize)\n",
    "        test_ds = datasets.ImageFolder('/home/MATLAB_DATA/TiNguyen/Sentry_Data/test', transform=transform_resize)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=params['batch_size'],\n",
    "                              shuffle=True, num_workers=params['num_workers'])\n",
    "    test_loader = DataLoader(test_ds, batch_size=params['batch_size'],\n",
    "                             shuffle=False, num_workers=params['num_workers'])\n",
    "\n",
    "    # Model init\n",
    "    sample_img, _ = train_ds[0]\n",
    "    c = ratio2filtersize(sample_img, params['ratio'])\n",
    "    print(f\"ðŸ”§ SNR={params['snr']}, inner channel c={c}, ratio={params['ratio']:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "    model = DeepJSCC(c=c, channel_type=params['channel'], snr=params['snr'], M =16, num_e_bits = 5, num_m_bits = 10)\n",
    "\n",
    "\n",
    "    ## model reference:\n",
    "    model_ref = load_model(params['ratio'])\n",
    "\n",
    "\n",
    "\n",
    "    model.encoder.load_state_dict(model_ref.encoder.state_dict())\n",
    "    model.decoder.load_state_dict(model_ref.decoder.state_dict())\n",
    "\n",
    "\n",
    "\n",
    "    model = setup_model_device(model, params)\n",
    "\n",
    "    # Optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['init_lr'], weight_decay=params['weight_decay'])\n",
    "    scheduler = setup_scheduler(optimizer, params)\n",
    "\n",
    "    # Logging directories\n",
    "    phaser = f\"{params['dataset'].upper()}_{c}_{params['snr']}_{params['ratio']:.2f}_{params['channel']}_{Nsamples}_{time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')}\"\n",
    "    # phaser = f\"{params['dataset'].upper()}_{c}_{params['snr']}_{params['ratio']:.2f}_{params['channel']}\"\n",
    "    log_dir = os.path.join(params['out_dir'], 'logs', phaser)\n",
    "    ckpt_dir = os.path.join(params['out_dir'], 'checkpoints', phaser)\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    writer.add_text('config', str(params))\n",
    "\n",
    "    t_start = time.time()\n",
    "    best_val = float('inf')\n",
    "\n",
    "    try:\n",
    "        for epoch in tqdm(range(params['epochs']), disable=params['disable_tqdm'], desc='Epoch'):\n",
    "            t0 = time.time()\n",
    "            train_loss = train_epoch(model, optimizer, params, train_loader, Nsamples)\n",
    "            val_loss = evaluate_epoch(model, params, test_loader)\n",
    "\n",
    "            writer.add_scalar('train_loss', train_loss, epoch)\n",
    "            writer.add_scalar('val_loss', val_loss, epoch)\n",
    "            writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            if epoch%10==0:\n",
    "                tqdm.write(f\"E{epoch} L_train={train_loss:.4f} L_val={val_loss:.4f} LR={optimizer.param_groups[0]['lr']:.4e} EpochTime={(time.time()-t0):.2f}s\")\n",
    "\n",
    "            # Save checkpoint\n",
    "            torch.save(model.state_dict(), os.path.join(ckpt_dir, f\"epoch_{epoch}.pth\"))\n",
    "            cleanup_checkpoints(ckpt_dir, keep_latest=1)\n",
    "\n",
    "            # Scheduler step\n",
    "            if params['ReduceLROnPlateau'] and scheduler:\n",
    "                scheduler.step(val_loss)\n",
    "            elif params['if_scheduler'] and scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            # Early stop trigger\n",
    "            if optimizer.param_groups[0]['lr'] < params['min_lr']:\n",
    "                print(\"LR dropped below minimum threshold.\")\n",
    "                break\n",
    "\n",
    "            # Optional: can implement early stopping here\n",
    "\n",
    "            # Time check\n",
    "            if time.time() - t_start > params['max_time'] * 3600:\n",
    "                print(\"Max training time reached, exiting.\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted by user.\")\n",
    "\n",
    "    # Final evaluation\n",
    "    final_train = evaluate_epoch(model, params, train_loader)\n",
    "    final_val = evaluate_epoch(model, params, test_loader)\n",
    "\n",
    "    print(f\"Done: Train Loss={final_train:.4f}, Val Loss={final_val:.4f}, TotalTime={(time.time()-t_start)/3600:.2f}h\")\n",
    "\n",
    "    # Save config YAML\n",
    "    config_path = os.path.join(params['out_dir'], 'configs', phaser + '.yaml')\n",
    "    os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.dump({'params': params, 'inner_channel': c, 'total_parameters': view_model_param(model)}, f)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def setup_model_device(model, params):\n",
    "    device = torch.device(params['device'])\n",
    "    if params['parallel'] and torch.cuda.device_count() > 1:\n",
    "        model = DataParallel(model).to(device)\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "    model.loss = model.module.loss if isinstance(model, DataParallel) else model.loss\n",
    "    params['device'] = device\n",
    "    params['parallel'] = params['parallel'] and torch.cuda.device_count() > 1\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_scheduler(optimizer, params):\n",
    "    if not params['if_scheduler']:\n",
    "        return None\n",
    "    if params['ReduceLROnPlateau']:\n",
    "        return optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "                                                    factor=params['lr_reduce_factor'],\n",
    "                                                    patience=params['lr_schedule_patience'])\n",
    "    else:\n",
    "        return optim.lr_scheduler.StepLR(optimizer, step_size=params['step_size'], gamma=params['gamma'])\n",
    "\n",
    "\n",
    "def cleanup_checkpoints(directory, keep_latest=2):\n",
    "    files = sorted(glob.glob(os.path.join(directory, 'epoch_*.pth')), key=os.path.getmtime)\n",
    "    old = files[:-keep_latest]\n",
    "    for f in old:\n",
    "        os.remove(f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Nsamples = 100 # for each encoded output, add Nsamples random channels\n",
    "    main_pipeline(Nsamples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JSCC2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
